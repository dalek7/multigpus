{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seung/.venv/py3Keras/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n",
      "/home/seung/.venv/py3Keras/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/seung/.venv/py3Keras/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/seung/.venv/py3Keras/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/seung/.venv/py3Keras/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/seung/.venv/py3Keras/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Conv2D, BatchNormalization, Activation, GlobalAveragePooling2D, AveragePooling2D, Dropout\n",
    "from keras.layers import UpSampling2D\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.datasets import cifar10\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle, os, zipfile, glob\n",
    "from tqdm import tqdm\n",
    "from keras import backend as K\n",
    "from keras.utils.training_utils import multi_gpu_model\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_Train = True\n",
    "#nb_labeled_data = 500\n",
    "nb_epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"result_supervised\"):\n",
    "        os.mkdir(\"result_supervised\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_conv_block(input, chs, rep):\n",
    "    x = input\n",
    "    for i in range(rep):\n",
    "        x = Conv2D(chs, 3, padding=\"same\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "    return x\n",
    "\n",
    "def create_cnn2():\n",
    "    from keras.applications import MobileNet\n",
    "    net = MobileNet(input_shape=(128,128,3), weights=None, include_top=False)\n",
    "    # upsampling(32->128)\n",
    "    input = Input((32,32,3))\n",
    "    x = UpSampling2D(4)(input)\n",
    "    x = net(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(10, activation=\"softmax\")(x)\n",
    "\n",
    "    model = Model(input, x)\n",
    "    #model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(n_labeled_data, n_epoch=1):\n",
    "    model = create_cnn2()\n",
    "    model.summary()\n",
    "    (X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "    K.image_data_format()\n",
    "    \n",
    "    indices = np.arange(X_train.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    y_test_true = np.ravel(y_test)\n",
    "    X_train = X_train[indices[:n_labeled_data]] / 255.0\n",
    "    X_test = X_test / 255.0\n",
    "    y_train = to_categorical(y_train[indices[:n_labeled_data]], 10)\n",
    "    y_test = to_categorical(y_test, 10)\n",
    "    #model = multi_gpu_model(model, gpus=2)\n",
    "    model.compile(\"adam\", loss=\"categorical_crossentropy\", metrics=[\"acc\"])\n",
    "\n",
    "    \n",
    "    t0 = time.time()\n",
    "    hist = model.fit(X_train, y_train, batch_size=min(n_labeled_data, 512),\n",
    "                     validation_data=(X_test, y_test), epochs=n_epoch, verbose=1).history\n",
    "    elapsed = time.time() - t0\n",
    "    print('elapsed = {}... {} per epoch'.format(elapsed, elapsed/n_epoch))\n",
    "    fn1 = \"result_supervised/history_{}.dat\".format(n_labeled_data)\n",
    "    \n",
    "    with open(fn1,  \"wb\") as fp:\n",
    "        pickle.dump(hist, fp)\n",
    "        print(fn1)\n",
    "\n",
    "    fnmodel = \"result_supervised/model_{}_{}.h5\".format('MobileNet', n_labeled_data)\n",
    "    model.save(fnmodel)\n",
    "    print('Saved model..... {}'.format(fnmodel))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 ---------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "mobilenet_1.00_128 (Model)   (None, 4, 4, 1024)        3228864   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 3,239,114\n",
      "Trainable params: 3,217,226\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0827 21:51:23.758337 139955186284288 deprecation_wrapper.py:119] From /home/seung/.venv/py3Keras/lib/python3.5/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0827 21:51:23.868537 139955186284288 deprecation.py:323] From /home/seung/.venv/py3Keras/lib/python3.5/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 113s 227ms/step - loss: 2.4455 - acc: 0.1320 - val_loss: 4.4160 - val_acc: 0.1001\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 109s 218ms/step - loss: 2.1586 - acc: 0.2480 - val_loss: 4.6995 - val_acc: 0.1189\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 109s 218ms/step - loss: 2.1652 - acc: 0.2600 - val_loss: 3.3950 - val_acc: 0.1219\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 109s 218ms/step - loss: 1.8835 - acc: 0.3540 - val_loss: 3.6696 - val_acc: 0.1345\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 109s 218ms/step - loss: 1.6528 - acc: 0.5480 - val_loss: 2.7055 - val_acc: 0.1548\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 109s 218ms/step - loss: 1.3683 - acc: 0.7540 - val_loss: 2.6994 - val_acc: 0.1640\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 109s 218ms/step - loss: 0.9637 - acc: 0.8900 - val_loss: 3.1444 - val_acc: 0.1305\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 109s 218ms/step - loss: 0.6028 - acc: 0.9780 - val_loss: 3.8855 - val_acc: 0.1105\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 109s 218ms/step - loss: 0.3316 - acc: 0.9880 - val_loss: 3.5985 - val_acc: 0.1267\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 109s 218ms/step - loss: 0.1342 - acc: 0.9960 - val_loss: 3.4024 - val_acc: 0.1545\n",
      "elapsed = 1096.155635356903... 109.61556353569031 per epoch\n",
      "result_supervised/history_500.dat\n",
      "Saved model..... result_supervised/model_MobileNet_500.h5\n"
     ]
    }
   ],
   "source": [
    "vtraining = [500, 1000, 5000, 10000]\n",
    "vtraining  = [500,  5000, 10000]\n",
    "vtraining  = [500,]\n",
    "for ntr in vtraining :\n",
    "    print('{} ---------------------'.format(ntr))\n",
    "    model1 = train(ntr, n_epoch=nb_epoch)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py35_keras",
   "language": "python",
   "name": "py35_keras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
